% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/inspect.R
\name{cbc_compare_designs}
\alias{cbc_compare_designs}
\title{Compare designs across multiple metrics}
\usage{
cbc_compare_designs(
  ...,
  errors = "d",
  include_metrics = TRUE,
  priors = NULL,
  exclude = NULL
)
}
\arguments{
\item{...}{Multiple \code{cbc_design} or \code{cbc_survey} objects to compare, or named
arguments where each argument is a design or survey object}

\item{errors}{Character vector specifying which error metrics to compute.
Options: "d" (D-error), "a" (A-error), "g" (G-error), "e" (E-error),
"all" (comprehensive metrics). Defaults to "d". When priors contain
random parameters, Bayesian versions are automatically computed.}

\item{include_metrics}{Logical. Include balance, overlap, and profile usage
metrics in addition to error metrics? Defaults to TRUE for comprehensive
comparison. Set to FALSE for error-only comparison.}

\item{priors}{Optional \code{cbc_priors} object to use for all designs/surveys. If not
specified, each object's own priors will be used.}

\item{exclude}{Character vector of attribute names to exclude from error
calculations}
}
\value{
A data frame comparing metrics across designs, sorted by primary
error metric (D-error by default)
}
\description{
This function compares multiple designs across various efficiency metrics
including error criteria, balance, overlap, and profile usage. Provides
flexible error type selection and comprehensive or simplified output.
}
\examples{
# Create profiles
profiles <- cbc_profiles(
  price = c(1, 2, 3),
  type = c("A", "B", "C")
)

# Create different designs
design_random <- cbc_design(profiles, n_alts = 2, n_q = 4, method = "random")

priors <- cbc_priors(
  profiles = profiles,
  price = -0.5,
  type = c(0.2, 0.3)
)

design_sequential <- cbc_design(
  profiles, priors = priors, n_alts = 2, n_q = 4, method = "sequential"
)

# Comprehensive comparison (default)
cbc_compare_designs(
  Random = design_random,
  Sequential = design_sequential
)

# Multiple error types with full metrics
cbc_compare_designs(
  Random = design_random,
  Sequential = design_sequential,
  errors = c("d", "a", "g")
)

# Error-only comparison
cbc_compare_designs(
  Random = design_random,
  Sequential = design_sequential,
  errors = c("d", "a"),
  include_metrics = FALSE
)
}
