% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/estimateModels.R
\name{estimateModels}
\alias{estimateModels}
\title{Estimate the same model on different size subsets of a data set}
\usage{
estimateModels(
  nbreaks = 10,
  nQPerResp = 1,
  data,
  outcome,
  obsID,
  pars,
  price = NULL,
  randPars = NULL,
  randPrice = NULL,
  modelSpace = "pref",
  weights = NULL,
  panelID = NULL,
  clusterID = NULL,
  robust = FALSE,
  startParBounds = c(-1, 1),
  startVals = NULL,
  numMultiStarts = 1,
  useAnalyticGrad = TRUE,
  scaleInputs = TRUE,
  standardDraws = NULL,
  numDraws = 50,
  vcov = FALSE,
  predict = FALSE,
  options = list(print_level = 0, xtol_rel = 1e-06, xtol_abs = 1e-06, ftol_rel = 1e-06,
    ftol_abs = 1e-06, maxeval = 1000, algorithm = "NLOPT_LD_LBFGS")
)
}
\arguments{
\item{nbreaks}{The number of different sample size groups.}

\item{nQPerResp}{Number of questions per respondent. Defaults to \code{1} if not
specified.}

\item{data}{The data, formatted as a \code{data.frame} object.}

\item{outcome}{The name of the column that identifies the outcome variable,
which should be coded with a \code{1} for \code{TRUE} and \code{0} for \code{FALSE}.}

\item{obsID}{The name of the column that identifies each observation.}

\item{pars}{The names of the parameters to be estimated in the model.
Must be the same as the column names in the \code{data} argument. For WTP space
models, do not include price in \code{pars}.}

\item{price}{The name of the column that identifies the price variable.
Required for WTP space models. Defaults to \code{NULL}.}

\item{randPars}{A named vector whose names are the random parameters and
values the distribution: \code{'n'} for normal or \code{'ln'} for log-normal.
Defaults to \code{NULL}.}

\item{randPrice}{The random distribution for the price parameter: \code{'n'} for
normal or \code{'ln'} for log-normal. Only used for WTP space MXL models.
Defaults to \code{NULL}.}

\item{modelSpace}{Set to \code{'wtp'} for WTP space models. Defaults to \code{"pref"}.}

\item{weights}{The name of the column that identifies the weights to be
used in model estimation. Defaults to \code{NULL}.}

\item{panelID}{The name of the column that identifies the individual (for
panel data where multiple observations are recorded for each individual).
Defaults to \code{NULL}.}

\item{clusterID}{The name of the column that identifies the cluster
groups to be used in model estimation. Defaults to \code{NULL}.}

\item{robust}{Determines whether or not a robust covariance matrix is
estimated. Defaults to \code{FALSE}. Specification of a \code{clusterID} or
\code{weights} will override the user setting and set this to `TRUE' (a
warning will be displayed in this case). Replicates the functionality of
Stata's cmcmmixlogit.}

\item{startParBounds}{sets the \code{lower} and \code{upper} bounds for the starting
parameters for each optimization run, which are generated by
\code{runif(n, lower, upper)}. Defaults to \code{c(-1, 1)}.}

\item{startVals}{is vector of values to be used as starting values for the
optimization. Only used for the first run if \code{numMultiStarts > 1}. Defaults
to \code{NULL}.}

\item{numMultiStarts}{is the number of times to run the optimization loop,
each time starting from a different random starting point for each parameter
between \code{startParBounds}. Recommended for non-convex models, such as WTP
space models and mixed logit models. Defaults to \code{1}.}

\item{useAnalyticGrad}{Set to \code{FALSE} to use numerically approximated
gradients instead of analytic gradients during estimation. For now, using
the analytic gradient is faster for MNL models but slower for MXL models.
Defaults to \code{TRUE}.}

\item{scaleInputs}{By default each variable in \code{data} is scaled to be
between 0 and 1 before running the optimization routine because it usually
helps with stability, especially if some of the variables have very large or
very small values (e.g. \verb{> 10^3} or \verb{< 10^-3}). Set to \code{FALSE} to turn this
feature off. Defaults to \code{TRUE}.}

\item{standardDraws}{By default, a new set of standard normal draws are
generated during each call to \code{logitr} (the same draws are used during each
multistart iteration). The user can override those draws by providing a
matrix of standard normal draws if desired. Defaults to \code{NULL}.}

\item{numDraws}{The number of Halton draws to use for MXL models for the
maximum simulated likelihood. Defaults to \code{50}.}

\item{vcov}{Set to \code{TRUE} to evaluate and include the variance-covariance
matrix and coefficient standard errors in the returned object.
Defaults to \code{FALSE}.}

\item{predict}{If \code{FALSE}, predicted probabilities, fitted values, and
residuals are not included in the returned object. Defaults to \code{TRUE}.}

\item{options}{A list of options for controlling the \code{nloptr()} optimization.
Run \code{nloptr::nloptr.print.options()} for details.}
}
\value{
Returns a nested data frame with each estimated model object in
the \code{model} column.
}
\description{
This function estimates the same model multiple times using different size
subsets of a set of choice data. The number of models to run is set by the
\code{nbreaks} argument, which breaks up the data into groups of increasing
sample sizes. All models are estimated models using the {logitr} package.
}
\examples{
library(conjointTools)

# Define the attributes and levels
levels <- list(
  price     = seq(1, 4, 0.5), # $ per pound
  type      = c('Fuji', 'Gala', 'Honeycrisp', 'Pink Lady', 'Red Delicious'),
  freshness = c('Excellent', 'Average', 'Poor')
)

# Make a full-factorial design of experiment and recode the levels
doe <- makeDoe(levels)
doe <- recodeDoe(doe, levels)

# Make the survey
survey <- makeSurvey(
    doe       = doe,  # Design of experiment
    nResp     = 2000, # Total number of respondents (upper bound)
    nAltsPerQ = 3,    # Number of alternatives per question
    nQPerResp = 6     # Number of questions per respondent
)

# Simulate random choices for the survey
data <- simulateChoices(
    survey = survey,
    obsID  = "obsID"
)

# Estimate models with different sample sizes
models <- estimateModels(
    nbreaks = 10,
    data    = data,
    pars    = c("price", "type", "freshness"),
    outcome = "choice",
    obsID   = "obsID"
)
}
\keyword{logit,}
\keyword{logitr,}
\keyword{mnl,}
\keyword{mxl,}
\keyword{power}
\keyword{sample}
\keyword{size,}
